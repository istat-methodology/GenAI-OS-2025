<div align="center">
    <img src="resources/unece-logo.png" alt="UNECE Logo">
</div>

<div align="center">
    <h3 align="center">
        Generative AI and Official Statistics Workshop 2025
    <h3>
</div>

<h1 align="center">
     Transformer-based Models for Official Statistics: A Tutorial
</h1>

<div align="center">
  <a href="https://www.researchgate.net/profile/Francesco-Ortame-3">
    <img src="https://img.shields.io/badge/Francesco%20Ortame-white?logo=researchgate" alt="Francesco Ortame">
  </a>
  <a href="https://www.researchgate.net/profile/Mauro-Bruno-2">
    <img src="https://img.shields.io/badge/Mauro%20Bruno-white?logo=researchgate" alt="Mauro Bruno">
  </a>
  <a href="https://www.researchgate.net/profile/Giulio-Massacci">
    <img src="https://img.shields.io/badge/Giulio%20Massacci-white?logo=researchgate" alt="Giulio Massacci">
  </a>
</div>

### Abstract
Transformer-based models have emerged as one of the most significant breakthroughs in machine learning, largely due to their ability to process and analyse natural language. Generative Transformers – like Large Language Models (LLMs) – paved the way for entirely new automated data analysis techniques. This, paired with the growing availability of textual data, from administrative sources to social media, presents great opportunities as well as specific challenges for National Statistical Institutes (NSIs) and Non-Governmental Organisations (NGOs). While flexible and powerful, Transformer models require vast amounts of data and significant computational power to be trained for most tasks. However, an ever-growing number of pre-trained models is available for download. These open-source or open-weight models can be utilized in their current form or fine-tuned to handle specific tasks through much smaller amounts of data compared to training from scratch. In this paper, we present streamlined pipelines for using and fine-tuning generative Transformers across several use cases, including (i) social media text classification, with a focus on explainability; (ii) estimation of enterprises’ economic activities via Retrieval Augmented Generation (RAG); (iii) automated aspect-based textual data labelling. We aim to provide the reader with best practices for integrating Transformer-based models in statistical production processes.
